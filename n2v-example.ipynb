{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T02:17:22.100819Z",
     "start_time": "2019-04-17T02:17:21.168338Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build_ext\r\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "!python3 setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T02:17:22.109287Z",
     "start_time": "2019-04-17T02:17:22.104622Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove console log and use file log \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(message)s',level=logging.INFO)\n",
    "\n",
    "# formatter = logging.Formatter('%(asctime)s %(message)s')\n",
    "\n",
    "# filelogger = logging.getLogger()\n",
    "\n",
    "# for h in filelogger.handlers:\n",
    "#     filelogger.removeHandler(h)\n",
    "\n",
    "# filelogger.setLevel(logging.INFO)\n",
    "# fh = logging.FileHandler(\"log.log\",mode='w')\n",
    "# fh.setLevel(logging.DEBUG)\n",
    "# fh.setFormatter(formatter)\n",
    "# filelogger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T02:17:22.483262Z",
     "start_time": "2019-04-17T02:17:22.111820Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhang18f/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from n2v_r import run\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_predict,train_test_split\n",
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "from sklearn.preprocessing import normalize,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T02:17:22.513864Z",
     "start_time": "2019-04-17T02:17:22.487559Z"
    }
   },
   "outputs": [],
   "source": [
    "datapath = '/home/zhang18f/datasets/Cora/'\n",
    "\n",
    "# import deepwalkDataIterator\n",
    "# dataIterator = deepwalkDataIterator.DataIterator('%s/edges.csv' % datapath, 'cora.deepwalk')\n",
    "\n",
    "import P2VDataIterator\n",
    "dataIterator = P2VDataIterator.DataIterator('%s' % datapath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T02:18:02.887769Z",
     "start_time": "2019-04-17T02:17:22.519087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-16 22:17:22,527 initializing cython module\n",
      "2019-04-16 22:17:22,548 cython module initialized\n",
      "2019-04-16 22:17:22,550 use P2V\n",
      "2019-04-16 22:17:22,551 use TF-ICF\n",
      "2019-04-16 22:17:22,553 initilize the model\n",
      "2019-04-16 22:17:22,554 loading data\n",
      "2019-04-16 22:17:22,659 data contains 2708 papers, 1432 words\n",
      "2019-04-16 22:17:22,667 pre-processing negative sampling for n2v\n",
      "2019-04-16 22:17:22,670 init embeddings\n",
      "2019-04-16 22:17:22,674 done\n",
      "2019-04-16 22:17:22,675 building node draw table\n",
      "2019-04-16 22:17:22,678 starting trainig threads with 20000000 samples\n",
      "2019-04-16 22:17:25,020 progress: 5.00%, 1M samples trained, current loss 0.5056, current speed 0.43M/s, overall speed 0.43M/s, ETA: 44s\n",
      "2019-04-16 22:17:26,981 progress: 10.00%, 2M samples trained, current loss 0.3515, current speed 0.51M/s, overall speed 0.46M/s, ETA: 38s\n",
      "2019-04-16 22:17:28,933 progress: 15.00%, 3M samples trained, current loss 0.3280, current speed 0.51M/s, overall speed 0.48M/s, ETA: 35s\n",
      "2019-04-16 22:17:30,897 progress: 20.00%, 4M samples trained, current loss 0.3222, current speed 0.51M/s, overall speed 0.49M/s, ETA: 32s\n",
      "2019-04-16 22:17:32,847 progress: 25.00%, 5M samples trained, current loss 0.3197, current speed 0.51M/s, overall speed 0.49M/s, ETA: 30s\n",
      "2019-04-16 22:17:35,326 progress: 30.00%, 6M samples trained, current loss 0.3185, current speed 0.40M/s, overall speed 0.47M/s, ETA: 29s\n",
      "2019-04-16 22:17:37,279 progress: 35.00%, 7M samples trained, current loss 0.3177, current speed 0.51M/s, overall speed 0.48M/s, ETA: 27s\n",
      "2019-04-16 22:17:39,230 progress: 40.00%, 8M samples trained, current loss 0.3168, current speed 0.51M/s, overall speed 0.48M/s, ETA: 24s\n",
      "2019-04-16 22:17:41,176 progress: 45.00%, 9M samples trained, current loss 0.3163, current speed 0.51M/s, overall speed 0.49M/s, ETA: 22s\n",
      "2019-04-16 22:17:43,123 progress: 50.00%, 10M samples trained, current loss 0.3161, current speed 0.51M/s, overall speed 0.49M/s, ETA: 20s\n",
      "2019-04-16 22:17:45,067 progress: 55.00%, 11M samples trained, current loss 0.3154, current speed 0.51M/s, overall speed 0.49M/s, ETA: 18s\n",
      "2019-04-16 22:17:47,010 progress: 60.00%, 12M samples trained, current loss 0.3152, current speed 0.51M/s, overall speed 0.49M/s, ETA: 16s\n",
      "2019-04-16 22:17:48,966 progress: 65.00%, 13M samples trained, current loss 0.3149, current speed 0.51M/s, overall speed 0.49M/s, ETA: 14s\n",
      "2019-04-16 22:17:50,915 progress: 70.00%, 14M samples trained, current loss 0.3144, current speed 0.51M/s, overall speed 0.50M/s, ETA: 12s\n",
      "2019-04-16 22:17:52,855 progress: 75.00%, 15M samples trained, current loss 0.3141, current speed 0.52M/s, overall speed 0.50M/s, ETA: 10s\n",
      "2019-04-16 22:17:54,809 progress: 80.00%, 16M samples trained, current loss 0.3139, current speed 0.51M/s, overall speed 0.50M/s, ETA: 8s\n",
      "2019-04-16 22:17:56,757 progress: 85.00%, 17M samples trained, current loss 0.3137, current speed 0.51M/s, overall speed 0.50M/s, ETA: 6s\n",
      "2019-04-16 22:17:58,698 progress: 90.00%, 18M samples trained, current loss 0.3133, current speed 0.52M/s, overall speed 0.50M/s, ETA: 4s\n",
      "2019-04-16 22:18:00,670 progress: 95.00%, 19M samples trained, current loss 0.3129, current speed 0.51M/s, overall speed 0.50M/s, ETA: 1s\n",
      "2019-04-16 22:18:02,632 progress: 100.00%, 20M samples trained, current loss 0.3127, current speed 0.51M/s, overall speed 0.50M/s, ETA: 0s\n",
      "2019-04-16 22:18:02,633 20000000 samples trained in 39 seconds\n",
      "2019-04-16 22:18:02,633 save embeddings to n2v.emb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "model = run(\n",
    "    dataIterator,\n",
    "    alg = 'n2v',\n",
    "    output='n2v.emb',\n",
    "    total_samples = 2e7,\n",
    "    p=0.85,\n",
    "    l2 = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T02:19:55.942596Z",
     "start_time": "2019-04-17T02:19:55.261278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.6410    0.7812    0.7042        32\n",
      "          1     0.7989    0.8935    0.8436       169\n",
      "          2     0.8039    0.7193    0.7593        57\n",
      "          3     0.9545    0.9438    0.9492        89\n",
      "          4     0.7193    0.5942    0.6508        69\n",
      "          5     0.8095    0.8095    0.8095        42\n",
      "          6     0.8947    0.8095    0.8500        84\n",
      "\n",
      "avg / total     0.8212    0.8192    0.8176       542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = open('%s/idxs.txt' % datapath)\n",
    "l = open('%s/labels.txt' % datapath)\n",
    "X = []\n",
    "Y = []\n",
    "labels = {}\n",
    "for idx,label in zip(i,l):\n",
    "    idx = idx.rstrip()\n",
    "    X.append(model.paper(idx))\n",
    "    label = label.rstrip()\n",
    "    if label not in labels:\n",
    "        labels[label] = len(labels)\n",
    "    Y.append(labels[label])\n",
    "    \n",
    "\n",
    "X = normalize(X)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,train_size=0.8,random_state=0)\n",
    "Y_predict = lg(random_state=0).fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,Y_predict,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
